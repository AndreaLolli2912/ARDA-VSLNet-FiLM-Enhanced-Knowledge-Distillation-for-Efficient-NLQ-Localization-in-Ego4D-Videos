{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Ensure we have downloaded the files correctly\n",
    "!ls drive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f53171",
   "metadata": {},
   "source": [
    "### Clone the Episodic Memory Baseline Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc426dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "git clone https://github.com/danielefam/episodic-memory\n",
    "cd episodic-memory\n",
    "git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331b69f5",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "The NLQ baseline repository for VSLNet requires you to prepare the data for training and evaluation purposes. From the [README.md](https://github.com/EGO4D/episodic-memory/blob/main/NLQ/VSLNet/README.md#preparation) we need to run the `prepare_ego4d_dataset.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a09578",
   "metadata": {},
   "source": [
    "### Setup Environment Variables for NLQ\n",
    "\n",
    "First let's setup some environment variables and setup the paths as NLQ's scripts will expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc2d86",
   "metadata": {},
   "source": [
    "Run the following if **VSLNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d9e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vars.sh\", \"w\") as out_f:\n",
    "  out_f.write(\"\"\"\n",
    "export NAME=egovlp_fp16\n",
    "export TASK_NAME=nlq_official_v1_$NAME\n",
    "export BASE_DIR=data/dataset/nlq_official_v1_$NAME\n",
    "export FEATURE_BASE_DIR=data/features/nlq_official_v1_$NAME\n",
    "export FEATURE_DIR=$FEATURE_BASE_DIR/video_features\n",
    "export MODEL_BASE_DIR=/content/nlq_official_v1/checkpoints/\n",
    "export GLOVE_DICTIONARY=data/features/glove.840B.300d.txt\n",
    "export ANNOTATION_PREPARED=data/dataset/nlq_official_v1_$NAME\n",
    "export VIDEO_PREPARED=$FEATURE_BASE_DIR/official\n",
    "export GDRIVE_PREPARED_ANNOTATION=/content/drive/MyDrive/prepared_features/$TASK_NAME/\n",
    "export GDRIVE_PREPARED_VIDEO=/content/drive/MyDrive/prepared_features/official/\n",
    "export DATASET_PATH=data/dataset\n",
    "\n",
    "cd episodic-memory/NLQ/VSLNet\n",
    "\"\"\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10adff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/features/nlq_official_v1_egovlp_fp16\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "source vars.sh\n",
    "\n",
    "echo $FEATURE_BASE_DIR\n",
    "mkdir -p $FEATURE_BASE_DIR\n",
    "mkdir -p $DATASET_PATH\n",
    "ln -s /content/drive/MyDrive/egovlp_fp16/ $FEATURE_DIR\n",
    "ln -s /content/drive/MyDrive/glove.840B.300d.txt $GLOVE_DICTIONARY\n",
    "ln -s $GDRIVE_PREPARED_ANNOTATION $ANNOTATION_PREPARED\n",
    "ln -s $GDRIVE_PREPARED_VIDEO $FEATURE_BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edef702",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "%%capture\n",
    "\n",
    "source vars.sh\n",
    "pip install nltk submitit torch torchaudio torchvision tqdm transformers tensorboard Pillow terminaltables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13b607",
   "metadata": {},
   "source": [
    "# Train and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaeb587",
   "metadata": {},
   "source": [
    "## Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef63e40",
   "metadata": {},
   "source": [
    "Please note:\n",
    "1. These are *not* the parameters for the original baseline model in the Ego4D whitepaper.\n",
    "2. Omnivore video features are used (slowfast was originally used), and their FP16 variant. This is due to free colab constraints (100GB disk space).\n",
    "\n",
    "Omnivore video features do out-perform slowfast features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e59c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b63ce",
   "metadata": {},
   "source": [
    "You may have to re-run this cell after you run the training script. You can try to reload data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa37c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!mkdir -p /content/episodic-memory/NLQ/VSLNet/runs/\n",
    "%tensorboard --logdir /content/episodic-memory/NLQ/VSLNet/runs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4175fd",
   "metadata": {},
   "source": [
    "Run the following if **VSLNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if you use glove\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14948b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "source vars.sh\n",
    "\n",
    "# machine parameters\n",
    "export DATALOADER_WORKERS=1\n",
    "export NUM_WORKERS=2\n",
    "export VAL_JSON_PATH=\"/content/drive/MyDrive/annotations/nlq_val.json\"\n",
    "\n",
    "# hyper parameters\n",
    "export BATCH_SIZE=16\n",
    "export DIM=128\n",
    "export NUM_EPOCH=30\n",
    "export MAX_POS_LEN=128\n",
    "export INIT_LR=0.0006\n",
    "\n",
    "export TB_LOG_NAME=\"${NAME}_bs${BATCH_SIZE}_dim${DIM}_epoch${NUM_EPOCH}_ilr${INIT_LR}\"\n",
    "\n",
    "python main.py \\\n",
    "    --task $TASK_NAME \\\n",
    "    --predictor glove \\\n",
    "    --dim $DIM \\\n",
    "    --mode train \\\n",
    "    --video_feature_dim 256 \\\n",
    "    --max_pos_len $MAX_POS_LEN \\\n",
    "    --init_lr $INIT_LR \\\n",
    "    --epochs $NUM_EPOCH \\\n",
    "    --batch_size $BATCH_SIZE \\\n",
    "    --fv official \\\n",
    "    --num_workers $NUM_WORKERS \\\n",
    "    --data_loader_workers $DATALOADER_WORKERS \\\n",
    "    --model_dir $MODEL_BASE_DIR/$NAME \\\n",
    "    --eval_gt_json $VAL_JSON_PATH \\\n",
    "    --log_to_tensorboard $TB_LOG_NAME \\\n",
    "    --tb_log_freq 5 \\\n",
    "    --remove_empty_queries_from train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec71e70",
   "metadata": {},
   "source": [
    "Da rivedere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b535db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict on test set.\n",
    "python main.py \\\n",
    "    --task nlq_official_v1 \\\n",
    "    --predictor bert \\\n",
    "    --mode test \\\n",
    "    --video_feature_dim 2304 \\\n",
    "    --max_pos_len 128 \\\n",
    "    --fv official \\\n",
    "    --model_dir checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7cec9",
   "metadata": {},
   "source": [
    "Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "source vars.sh\n",
    "\n",
    "# machine parameters\n",
    "export DATALOADER_WORKERS=1\n",
    "export NUM_WORKERS=2\n",
    "export VAL_JSON_PATH=\"/content/drive/MyDrive/annotations/nlq_val.json\"\n",
    "BATCH_SIZEs=(16 32)\n",
    "DIMs=(128)\n",
    "INIT_LRs=(0.001 0.0025)\n",
    "\n",
    "for BATCH_SIZE_it in ${BATCH_SIZEs[@]}; do\n",
    "  for DIM_it in ${DIMs[@]}; do\n",
    "    for INIT_LR_it in ${INIT_LRs[@]}; do\n",
    "\n",
    "      export BATCH_SIZE=$BATCH_SIZE_it\n",
    "      export DIM=$DIM_it\n",
    "      export INIT_LR=$INIT_LR_it\n",
    "      export NUM_EPOCH=2\n",
    "      export MAX_POS_LEN=128\n",
    "\n",
    "      export TB_LOG_NAME=\"${NAME}_bs${BATCH_SIZE}_dim${DIM}_epoch${NUM_EPOCH}_ilr${INIT_LR}\"\n",
    "\n",
    "      python main.py \\\n",
    "          --task $TASK_NAME \\\n",
    "          --predictor bert \\\n",
    "          --dim $DIM \\\n",
    "          --mode train \\\n",
    "          --video_feature_dim 256 \\\n",
    "          --max_pos_len $MAX_POS_LEN \\\n",
    "          --init_lr $INIT_LR \\\n",
    "          --epochs $NUM_EPOCH \\\n",
    "          --batch_size $BATCH_SIZE \\\n",
    "          --fv official \\\n",
    "          --num_workers $NUM_WORKERS \\\n",
    "          --data_loader_workers $DATALOADER_WORKERS \\\n",
    "          --model_dir $MODEL_BASE_DIR/$NAME \\\n",
    "          --eval_gt_json $VAL_JSON_PATH \\\n",
    "          --log_to_tensorboard $TB_LOG_NAME \\\n",
    "          --tb_log_freq 5 \\\n",
    "          --remove_empty_queries_from train\n",
    "\n",
    "    done\n",
    "  done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574cbfd",
   "metadata": {},
   "source": [
    "plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72392fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3580), started 0:43:22 ago. (Use '!kill 3580' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!mkdir -p /content/episodic-memory/NLQ/VSLBase/runs/\n",
    "%tensorboard --logdir /content/episodic-memory/NLQ/VSLNet/runs/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
