{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3baf1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.ao.quantization import default_qconfig\n",
    "from torch.ao.quantization.fuse_modules import fuse_modules\n",
    "\n",
    "\n",
    "from model.DeepVSLNet import DeepVSLNet\n",
    "from model.QuantizedDeepVSLNet import QuantizedDeepVSLNet\n",
    "from model.layers import Conv1DReLU, Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6241e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_sequential_block(\n",
    "    block: nn.Sequential,\n",
    "    layers_to_fuse: list[str],\n",
    "    inplace: bool = False\n",
    ") -> nn.Sequential:\n",
    "    \"\"\"\n",
    "    Fuse specified layers in a Sequential block.\n",
    "    \"\"\"\n",
    "    return torch.quantization.fuse_modules(block, layers_to_fuse, inplace=inplace)\n",
    "\n",
    "def fuse_modulelist_blocks(\n",
    "    blocks: nn.ModuleList,\n",
    "    fuse_map: list[str],\n",
    "    inplace: bool = False\n",
    ") -> nn.ModuleList:\n",
    "    \"\"\"\n",
    "    Applies fusion to each nn.Sequential in a ModuleList using a fixed fuse pattern.\n",
    "    \"\"\"\n",
    "    fused = []\n",
    "    for block in blocks:\n",
    "        block_copy = block if inplace else copy.deepcopy(block)\n",
    "        fused_block = fuse_sequential_block(block_copy, fuse_map, inplace=inplace)\n",
    "        fused.append(fused_block)\n",
    "    return nn.ModuleList(fused)\n",
    "\n",
    "def fuse_depthwise_separable_conv_block(conv_block, inplace=False):\n",
    "    \"\"\"\n",
    "    Fuses the pointwise Conv1d + ReLU in a DepthwiseSeparableConvBlock.\n",
    "    \"\"\"\n",
    "    conv_block_copy = conv_block if inplace else copy.deepcopy(conv_block)\n",
    "    fuse_pattern = ['1', '2']  # pointwise conv + ReLU\n",
    "    conv_block_copy.depthwise_separable_conv = fuse_modulelist_blocks(\n",
    "        conv_block_copy.depthwise_separable_conv,\n",
    "        fuse_map=fuse_pattern,\n",
    "        inplace=inplace\n",
    "    )\n",
    "    return conv_block_copy\n",
    "\n",
    "def fuse_feature_encoder(feature_encoder, inplace=False):\n",
    "    \"\"\"\n",
    "    Fuses all submodules in the feature encoder.\n",
    "    \"\"\"\n",
    "    encoder = feature_encoder if inplace else copy.deepcopy(feature_encoder)\n",
    "    encoder.conv_block = fuse_depthwise_separable_conv_block(encoder.conv_block, inplace=inplace)\n",
    "    return encoder\n",
    "\n",
    "def fuse_conv1d_relu_in_sequential(seq: nn.Sequential) -> nn.Sequential:\n",
    "    layers = []\n",
    "    i = 0\n",
    "    while i < len(seq):\n",
    "        if (\n",
    "            isinstance(seq[i], Conv1D)\n",
    "            and i + 1 < len(seq)\n",
    "            and isinstance(seq[i + 1], nn.ReLU)\n",
    "        ):\n",
    "            fused = Conv1DReLU(seq[i])\n",
    "            layers.append(fused)\n",
    "            i += 2  # skip next\n",
    "        else:\n",
    "            layers.append(seq[i])\n",
    "            i += 1\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def fuse_predictor_head(predictor_head: nn.Sequential, inplace=False) -> nn.Sequential:\n",
    "    block = predictor_head if inplace else copy.deepcopy(predictor_head)\n",
    "    return fuse_conv1d_relu_in_sequential(block)\n",
    "\n",
    "def fuse_conditioned_predictor(conditioned_predictor, inplace=False):\n",
    "    \"\"\"\n",
    "    Fuses encoder and start/end heads in a conditioned predictor module.\n",
    "    \"\"\"\n",
    "    predictor = conditioned_predictor if inplace else copy.deepcopy(conditioned_predictor)\n",
    "    predictor.encoder = fuse_feature_encoder(predictor.encoder, inplace=inplace)\n",
    "    predictor.start_block = fuse_predictor_head(predictor.start_block, inplace=inplace)\n",
    "    predictor.end_block = fuse_predictor_head(predictor.end_block, inplace=inplace)\n",
    "    return predictor\n",
    "\n",
    "def fuse_model(model, inplace=False):\n",
    "    \"\"\"\n",
    "    Top-level model fusion function.\n",
    "    \"\"\"\n",
    "    model_copy = model if inplace else copy.deepcopy(model)\n",
    "    model_copy.feature_encoder = fuse_feature_encoder(model_copy.feature_encoder, inplace=inplace)\n",
    "    model_copy.predictor = fuse_conditioned_predictor(model_copy.predictor, inplace=inplace)\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e85d348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedDeepVSLNet(\n",
       "  (query_quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (video_quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       "  (video_affine): VisualProjection(\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (linear): Conv1D(\n",
       "      (conv1d): Conv1d(\n",
       "        256, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cq_attention): CQAttention(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (cqa_linear): Conv1D(\n",
       "      (conv1d): Conv1d(\n",
       "        1024, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cq_concat): CQConcatenate(\n",
       "    (weighted_pool): WeightedPool()\n",
       "    (conv1d): Conv1D(\n",
       "      (conv1d): Conv1d(\n",
       "        512, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (highlight_layer): HighLightLayer(\n",
       "    (conv1d): Conv1D(\n",
       "      (conv1d): Conv1d(\n",
       "        256, 1, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictor): ConditionedPredictor(\n",
       "    (encoder): FeatureEncoder(\n",
       "      (pos_embedding): PositionalEmbedding(\n",
       "        (position_embeddings): Embedding(\n",
       "          128, 256\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (conv_block): DepthwiseSeparableConvBlock(\n",
       "        (depthwise_separable_conv): ModuleList(\n",
       "          (0-3): 4 x Sequential(\n",
       "            (0): Conv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,), groups=256, bias=False\n",
       "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "            )\n",
       "            (1): ConvReLU1d(\n",
       "              (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "              (1): ReLU()\n",
       "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "            )\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (layer_norms): ModuleList(\n",
       "          (0-3): 4 x LayerNorm(\n",
       "            (256,), eps=1e-06, elementwise_affine=True\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (attention_block): MultiHeadAttentionBlock(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (query): Conv1D(\n",
       "          (conv1d): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "        (key): Conv1D(\n",
       "          (conv1d): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "        (value): Conv1D(\n",
       "          (conv1d): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm1): LayerNorm(\n",
       "          (256,), eps=1e-06, elementwise_affine=True\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm(\n",
       "          (256,), eps=1e-06, elementwise_affine=True\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (out_layer): Conv1D(\n",
       "          (conv1d): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (film_after_pos): FiLM(\n",
       "        (film_generator): Linear(\n",
       "          in_features=256, out_features=512, bias=True\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (film_after_conv): FiLM(\n",
       "        (film_generator): Linear(\n",
       "          in_features=256, out_features=512, bias=True\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (film_after_attn): FiLM(\n",
       "        (film_generator): Linear(\n",
       "          in_features=256, out_features=512, bias=True\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (start_layer_norm): LayerNorm(\n",
       "      (256,), eps=1e-06, elementwise_affine=True\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "    (end_layer_norm): LayerNorm(\n",
       "      (256,), eps=1e-06, elementwise_affine=True\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "    (start_block): Sequential(\n",
       "      (0): Conv1DReLU(\n",
       "        (conv1d): Conv1d(\n",
       "          512, 256, kernel_size=(1,), stride=(1,)\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Conv1D(\n",
       "        (conv1d): Conv1d(\n",
       "          256, 1, kernel_size=(1,), stride=(1,)\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (end_block): Sequential(\n",
       "      (0): Conv1DReLU(\n",
       "        (conv1d): Conv1d(\n",
       "          512, 256, kernel_size=(1,), stride=(1,)\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Conv1D(\n",
       "        (conv1d): Conv1d(\n",
       "          256, 1, kernel_size=(1,), stride=(1,)\n",
       "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding_net): Embedding(\n",
       "    (word_emb): WordEmbedding(\n",
       "      (word_emb): Embedding(\n",
       "        300, 300, padding_idx=0\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (char_emb): CharacterEmbedding(\n",
       "      (char_emb): Embedding(\n",
       "        1000, 50, padding_idx=0\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "      (char_convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(\n",
       "            50, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(\n",
       "            50, 20, kernel_size=(1, 2), stride=(1, 1)\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(\n",
       "            50, 30, kernel_size=(1, 3), stride=(1, 1)\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(\n",
       "            50, 40, kernel_size=(1, 4), stride=(1, 1)\n",
       "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (linear): Conv1D(\n",
       "      (conv1d): Conv1d(\n",
       "        400, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = Namespace(\n",
    "    video_feature_dim=256,\n",
    "    dim=256,\n",
    "    film_mode=\"inside_encoder:multi\",\n",
    "    drop_rate=0,\n",
    "    word_size=300,\n",
    "    char_size=1000,\n",
    "    word_dim=300,\n",
    "    char_dim=50,\n",
    "    word_vectors=None,\n",
    "    num_heads=8,\n",
    "    max_pos_len=128,\n",
    "    predictor=\"glove\",\n",
    ")\n",
    "\n",
    "# 1. Load your original model\n",
    "model = DeepVSLNet(configs=configs, word_vectors=None)\n",
    "model.eval()\n",
    "\n",
    "# 2. Apply fusion\n",
    "fused = fuse_model(model, inplace=False)\n",
    "\n",
    "# 3. Wrap for quantization\n",
    "quant_model = QuantizedDeepVSLNet(fused)\n",
    "quant_model.qconfig = torch.ao.quantization.default_qconfig\n",
    "\n",
    "# 4. Prepare\n",
    "torch.quantization.prepare(quant_model, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ego4D-NLQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
